\documentclass[letterpaper,twocolumn,10pt]{article}
\usepackage{usenix,endnotes,multirow}
\usepackage{cleveref,amsmath,chngcntr}
\usepackage{epsfig,subfigure,framed}
%\usepackage{multicol,tabularx}
\usepackage{textcomp} % for tilde
\usepackage{paralist} % for in-paragraph lists


% Used for code snippets
\usepackage{listings,courier}

% Used for changing the spacing after the title, sections, and subsections.
\usepackage{titlesec,titling}

% Make text in figure captions small
\usepackage{caption3} % load caption package kernel first
\DeclareCaptionOption{parskip}[]{} % disable "parskip" caption option
\usepackage[small]{caption}

% Make sure that figure numbers are continuous through the document
\counterwithout{figure}{section}
\counterwithout{figure}{subsection}

% Settings on code listings.
\lstset{language=C,
		xleftmargin=0pt,
		xrightmargin=0pt,
		framexbottommargin=0pt,
        framextopmargin=0pt,
        framesep=0pt}

% Modify spacing before/after title, sections, and subsections.
\setlength{\droptitle}{-3em} 
\posttitle{\par\end{center}\vspace{-1.5em}}


\titlespacing\section{0pt}{5pt plus 4pt minus 2pt}{5pt plus 2pt minus 2pt}        
\titlespacing\subsection{0pt}{5pt plus 4pt minus 2pt}{5pt plus 2pt minus 2pt}   

% Compressed enumerations
\newenvironment{enumerate*}%
  {\begin{enumerate}%
    \setlength{\itemsep}{2pt}%
    \setlength{\parskip}{0pt}}%
  {\end{enumerate}}

% Compressed bibliograpgy
%\let\ORIGbibliography\bibliography
%\renewcommand{\bibliography}[1]{{\footnotesize \ORIGbibliography{#1}}}

% Add a horizontal rule above captions, and make captions closer to their figures
\DeclareCaptionFormat{ruled_caption}{#1#2#3\hrulefill}
\captionsetup[figure]{format=ruled_caption}
\let\ORIGcaption\caption
\renewcommand{\caption}[2][\compressedcaption]{%
\def\compressedcaption{#2}%
    \vspace{-12pt}%
    \ORIGcaption[#1]{#2}%
    \vspace{-12pt}}

% Decrease spacing before \paragraphs
\titlespacing{\paragraph}{%
  0pt}{%              left margin
  0.25\baselineskip}{% space before (vertical)
  1em}%               space after (horizontal)

% Prevent footnotes from spanning multiple pages
\interfootnotelinepenalty=10000

% For leaving some comments in the draft.
\newcommand{\comment}[1]{}

% Customize cleverref
\crefname{section}{Section}{Sections}

\begin{document}

%don't want date printed
\date{}

%make title bold and 14 pt font (Latex default is non-bold, 16 pt)
\title{\Large \bf Granary: A Sane Framework for Instrumenting an Insane Environment}

%for single author (just remove % characters)
\author{
{\rm Peter Goodman} \hspace{1.5em} {\rm Akshay Kumar} \hspace{1.5em} {\rm Angela Demke Brown} \hspace{1.5em} {\rm Ashvin Goel}\\
University of Toronto
} % end author


\maketitle
\subsection*{Abstract}
TODO

% Features:
%   1)  Mixed-mode execution:
%       i)  Control-flow driven execution:
%           -   Only instrument module code.
%           -   Only instrument kernel code.
%           -   Instrument both module and kernel code in different ways.
%           -   Only instrument particular functions.
%       ii)     Data-driven execution:
%           -   Watchpoints: trigger instrumentation when a watched address is dereferenced
%       iii)    Designed to "attach"/"detach" with zero overhead.
%   2)  Execution environments:
%       i)  User space.
%       ii)     Kernel space.
%   3)  Execution contexts:
%       i)  Native, uninstrumented code.
%       ii)  Instrumented code.
%       iii)    Granary.
%   4)  Instrumentation policies:
%       i)  Code can be simultaneously instrumented in different ways.
%       ii)     The way in which code is instrument can be context-specific or data-specific.
%   5)  Global/shared code cache.
%   X)  Stateless.
%
% Benefits:
%   1)  Mixed-mode execution:
%       -   Efficient: Overhead introduced by binary instrumentation can be limited by instrumenting less.
%       -   Flexible: Not required to instrument all code.
%   2)  Execution environments:
%       i)  User space:
%           -   Easy to test.
%       ii) Kernel space:
%           -   Few instrumentation options for kernel code (PinOS, QEMU, kvm, DynamoRIO Kernel), none
%               with same flexibility.
%   3)  Execution contexts:
%       i)  Native, uninstrumented code.
%           -   Code runs at full speed.
%       ii) Instrumented code.
%           -   Code behaves the same, but also runs additional application-specific code (e.g. memory access
%               checker).
%   4)  Instrumentation policies:
%       -   Overhead introduced by binary instrumentation can be limited by using a light-weight
%           policies on some code and heavy-weight policies on other code.
%   5)  Global/shared code cache.
%       -   All threads and cores see a consistent view instrumented code.
%       -   No duplication accross threads/cores, i.e. smaller memory footprint.
%   X)  Stateless:
%       -   No bookkeeping, and so no chance of Granary entering an inconsistent state.

\section{Introduction}\label{sec:intro}
%Granary is a new dynamic binary translation (DBT) framework created to instrument the Linux kernel, its modules, and user space Mac OS X and Linux programs.
%The main contribution of our work is the design and implementation of a \emph{mixed-mode} binary translation framework: Granary 
%Granary is novel because it excels at \emph{mixed-mode execution}: Granary is designed to switch between native and \emph{instrumented} code, as well as to switch between different instrumentation \emph{policies}.

Kernel modules extend the functionality of operating systems (OSes). Modules add support for new devices (e.g. network and graphics cards) and features (e.g. file systems). The kernel and its modules execute in a complex and dynamic environment. Understanding how modules behave in and affect this environment is important. However, analysing module behavior is challenging. Reasoning about module behaviour requires understanding the kernel/module interface (thousands of functions and shared data structures), as well as scheduling/concurrency concerns and interrupts/exceptions. Some modules are only distributed as binary executables and others cannot execute using existing virtualisation technologies.

Analysing modules also has benefits: regardless of how a module is programmed, it must use (or can be restricted to use) the kernel/module interface. This interface is known ahead of time (via the kernel source code) and is used by the kernel in a predictable way. The privileged nature of the kernel environment means that interrupts can be ``tamed'' and that tools can use privileged hardware features that are not available to user space analysis tools.



%the interface between modules and the kernel is known ahead of time and is used by the kernel in a predictable way, and interrupts

%These challenges motivate a solution that has a deep understanding of the kernel/module interface, can operate on arbitrary binaries, and does not require virtualisation to work.

%Therefore, any tool for comprehensively analysing all modules must be able to operate on binaries and without support for virtualisation.

%Modules interact with the kernel using a large API (thousands of functions) and share a lot of data over that API. 

%share a lot of data with the kernel and  

%Previous work has two limitations: 1) it has focused on complete binary instrumentation (i.e., instrumenting all code) to ensure transparency (... define transparency). In practice, we would like to have flexible instrumentation policies, that allow simply not instrumenting some code at all for efficiency, while also allowing rich/detailed instrumentation of relevant code. Example 1) only instrument module code without adding any instrumentation overhead while running normal kernel code, 2) watchpoint example, 3) instrument only shared accesses, 3) instrument differently for SIMD versus not. The second limitation of current systems is that they don't allow using static type information in the instrumentation code. Give example of why that is useful for possibly the four cases described above. Based on these limitations, our approach introduces mixed-mode execution, which enables implementing rich instrumentation policies, and a method for unifying static and dynamic instrumentation. Explain how mixed-mode execution handles transparency ...

The aforementioned challenges and benefits motivated the creation of Granary: a new dynamic binary translation (DBT) framework for instrumenting Linux kernel modules. Granary has a deep understanding of the kernel/module interface, can operate on arbitrary module binaries, and does not require virtualisation to work. The goal of Granary was to create a framework that makes it easy for developers to create flexible and dynamic instrumentation tools. Previous work has three limitations:  \begin{inparaenum}[i)]
	\item it has focused on instrumenting all code (e.g. the whole kernel or whole system); 
	\item it does not allow for the instrumentation policy to change dynamically; or
	\item it does not allow mixing static type information into the instrumentation code.
\end{inparaenum} 

Instrumenting all code (e.g. the whole kernel) imposes unnecessary performane overheads when one's goal is to analyse modules. In practice, we would like to target instrumentation at specific module code for efficiency, while also allowing rich/detailed instrumentation of the relevant code. This motivated the design of \emph{mixed-mode execution} in Granary: Granary can instrument modules without imposing any overhead on non-module kernel code by running that code natively. This is beneficial because if module code is not being actively used by the kernel then the kernel executes at full speed.

We would also like to be able to dynamically change how code is instrumented in response to changing conditions. For example,  we sometimes want to implement different ``levels'' or ``weights'' of instrumentation that apply lightweight/null instrumentation to the majority of code, and heavyweight instrumentation to only some code. This is challenging to do in existing  systems because: \begin{inparaenum}[i)]
	\item this feature is not supported by default; and
	\item the mechanisms used to maintain state about the code being instrumented make this feature hard to implement.
\end{inparaenum} We attempted to implement different levels of instrumentation in DynamoRIO Kernel (DRK)---an existing kernel DBT framework; however, this required changing how DRK handles interrupts, stores instrumented code, and maintains the consistency of its CPU-private state. The challenges faced when trying to implement dynamically changing instrumentation in DRK motivated the design of \emph{policy-driven instrumentation} in Granary.

Module analysis tools created using Granary can dynamically change how code is instrumented by switching the policy used to instrument code. One example of a problem that is well-suited to a policy-switching solution is ensuring that injected instrumentation code (e.g. that inspects function argument registers) is executed only once on entry to a function. This is challenging to do in some binary instrumentation systems because the first few instructions of a function might be re-executed within the function. In Granary, we can easily solve this problem by applying one policy ($P_{call\_entry}$)  to every \texttt{call} instruction, and another policy ($P_{after\_entry}$) to every non-\texttt{call} control-flow instruction.  The effect of this application of policies is that the first basic block executed on entry to a function will be instrumented by $P_{call\_entry}$; however, if the same basic block is targeted by a non-\texttt{call} instruction (e.g. a backward branch) then a second version of that basic block will be instrumented by $P_{after\_entry}$.

%Granary will ensure that the code targeted by \texttt{call} instructions will be instrumented according to $P_{call\_entry}.

%a common instrumentation problem is ensuring that added instrumentation code executes only once on entry to a function (regardless of if the first instructions of a function are re-executed within the function).

%, then one 

%For example, policy switching can be used to implement simple things like measuring module performance by reading the time stamp counter every $N$th basic block, or more complex things like switching from a lightweight $P_{null}$ policy to a heavyweight $P_{check\_shared}$ policy when a basic block instrumented by $P_{null}$ acquires a lock.

Policy switching is also useful in the context of interrupts. For example, Granary provides a framework for fine-grained memory access instrumentation, called \emph{behavioural watchpoints}. Behavioural watchpoints-based tools expose tainted memory addresses to instrumented programs. If a tainted address is used to access memory then the processor raises a fault. Instead of instrumenting all code in a way that guards against such faults ($P_{watchpoints}$), Granary defaults to instrumenting basic blocks using $P_{null}$. However, when a fault is raised, Granary prevents future faults from occuring within the same basic block by patching the $P_{null}$-instrumented basic block to re-route control to a $P_{watchpoints}$-instrumented basic block.

The last limitation of current systems is that they don't allow one to use static program information and instrument arbitrary, binary modules.  Existing systems for analysing modules fall into one of three categories: \begin{inparaenum}[i)]
	\item static/dynamic binary analysis tools that give low-level access to instructions and possibly memory;
	\item static analysis tools that give high-level access to the program's source code and semantics; and 
	\item mixed static/dynamic tools that have both high- and low-level access to program information.
\end{inparaenum} Systems falling into the above categories either: \begin{inparaenum}[i)]
	\item don't give access to high-level, ``big picture'' information available to static analysis;
	\item require source code and don't give access to low-level information (e.g. instructions, interrupts/scheduling, memory); or
	\item require source code and changes to the compilation toolchain.
\end{inparaenum} Despite these limitations, the benefits of static analysis motivated the design of a mixed static/dynamic analysis approach in Granary called \emph{reifying instrumentation}.

Granary statically analyses the Linux kernel source code to learn about  the interfaces that enable modules and the kernel to interact. Granary exposes this information to instrumentation tools in the form of type and function \emph{wrappers}. Tools can use this information to decide what policy to apply when instrumenting certain module code as well as to inspect and manipulate parts of module/kernel memory in a type-safe way.

For example, we are actively developing a tool that uses reifying instrumentation in conjunction with behavioural watchpoints to learn about what fields of what kernel data structures modules read from and write to over the course of their execution. This information allows us to model things like how a typical file system operates on kernel data structures in the process of opening a file. From these models, we can construct behavioural patterns about how modules use kernel data structures and functions. These patterns can be used to classify modules and identify spurious behaviour.

%Mixed static/dynamic analysis tools, however, make the best of both worlds: a compiler can use static information and generate optimised instrumentation that cooperates with a runtime system. We appreciate the benefits of a mixed approach; however, one of Granary's goals was to enable developers to create tools that instrument arbitrary, binary modules. We also recognised that existing compiler-based mixed approaches suffer other problems such as being limited to one instrumentation policy.

%These desires motivated the design of \emph{policy-driven instrumentation} in Granary.

%Instrumenting all code has the benefit of transparency: the behaviour of the code is not changed by the presence of instrumentation. In practice, we would like to target instrumentation at only specific code for efficiency, while allowing rich/detailed instrumentation of the relevant code.

%Maintaining transparency when not instrumenting all code is challenging. In practice, we would like to have flexible instrumentation and not 


 %(... define transparency). In practice, we would like to have flexible instrumentation policies, that allow simply not instrumenting some code at all for efficiency, while also allowing rich/detailed instrumentation of relevant code. Example 1) only instrument module code without adding any instrumentation overhead while running normal kernel code, 2) watchpoint example, 3) instrument only shared accesses, 3) instrument differently for SIMD versus not. The second limitation of current systems is that they don't allow using static type information in the instrumentation code. Give example of why that is useful for possibly the four cases described above. Based on these limitations, our approach introduces mixed-mode execution, which enables implementing rich instrumentation policies, and a method for unifying static and dynamic instrumentation. Explain how mixed-mode execution handles transparency 
%
%\iffalse
%
%	Existing approaches of statically analysing modules are unsatisfactory because they either: \begin{inparaenum}[i)]
%		\item depend on module source code, which is not always available;
%		\item operate on binaries, which are not always analysable; or
%		\item require source code changes to the kernel, its modules, or the compiler toolchain, which limits adoption and portability.
%	\end{inparaenum}
%	Static analysis of modules is challenging because of the tight interaction between the kernel and its modules.
%	
%	Existing approaches of dynamically analysing modules are also unsatisfactory because they either: \begin{inparaenum}[i)]
%		\item depend on hardware virtualisation, which limits which modules can be analysed;
%		\item depend on ``unstripped'' binaries that include debugging information; or
%		\item require one to instrument either the whole kernel or the whole system just to analyse one module.
%	\end{inparaenum}
%	
%	\subsection{Design and Motivation}
%	
%	The paper describes Granary: a new dynamic binary translation (DBT) framework created to instrument the Linux kernel and its modules. Granary does not depend on hardware virtualisation, source code availability/changes, compiler changes, or debugging information. Granary's key novelties are:
%	\begin{inparaenum}[i)]
%		\item its ability to dynamically change how code is instrumented, called \emph{policy-driven instrumentation};
%		\item its ability to maintain control while switching between native and instrumented code, called \emph{mixed-mode execution}; and
%		\item its ability to tie static program information lost through compilation back into a program binary, called \emph{reifying instrumentation}.
%	\end{inparaenum}
%	
%	Granary's development was motivated by our experience with trying to instrument kernel modules using DynamoRIO Kernel (DRK). DRK is a faithful kernel space port of the DynamoRIO DBT framework. We discovered that the user space conditions that influenced the design of DynamoRIO (and subsequently DRK) introduced unnecessary challenges when creating module analysis tools. The key challenges with using DRK to analyse modules were: \begin{inparaenum}[i)]
%		\item managing state was difficult;
%		\item transparency was prioritised to the detriment of flexibility; and
%		\item there was no consideration for understanding high-level program behaviour.
%	%low-level binary manipulation took precedence over tools for understanding high-level program behaviour.
%	%the ``binary'' in dynamic binary translation was overemphasized with no 
%	% low-level in DBT was overemphasized which led to a complete lack of high-level 
%	
%	%the understanding of high-level program behaviour was replaced by the sole focus on low-level binary manipulation.
%	
%	%the focus on low-level binary manipulation made it challenging to reason about overall module behaviour.
%	\end{inparaenum}
%	
%	%Granary was originally developed as an extension of DynamoRIO Kernel (DRK)---a kernel space port of the DynamoRIO DBT framework. However, our extended version of DRK failed as a compelling framework for module analsysis. While developing the original version of Granary, we faced several challenges relating to DRK's design. Key among these challenges were: managing state, transparency, and tooling.
%	
%	%DRK is a faithful port of DynamoRIO insofar as user space 
%	
%	%because of unforseen challenges arising from DynamoRIO's focus on user space instrumentation. Key among these challenges were: managing state, transparency, and tooling.
%	
%	%However, we faced many challenges when extending DRK to instrument only modules
%	
%	%We chose DRK because it enabled low-level instrumentation of the Linux kernel and its modules. DRK seemed ideal because it does not depend on hardware virtualisation, source code availability/changes, compiler changes, or debugging information.
%	
%	%, which motivated the creation of Granary: a new DBT framework for analysing the kernel and its modules. Key among these challenges were: managing state, transparency, and tooling.
%	
%	\paragraph{State Management} DRK maintains control over the execution of instrumented code by tracking what code is executing on each CPU. However, maintaining the consistency of this state is challenging: interrupts and exceptions introduce re-entrancy issues that must be solved on a case-by-case basis. The complexities of managing the existing state increased when we modified DRK to only instrument modules and not the kernel.
%	
%	%tracks what code is executing on each CPU. Maintaining the consistency of this state is challenging. Threads of execution are regularly interrupted on one CPU and resumed on another. Therefore, CPU-private state relating to the execution of those threads must be correctly marshalled across CPUs.
%	
%	%Ensuring that this state remains consistent is challenging. Instrumented threads are regularly interrupted or request to be re-scheduled. Resumed threads sometimes execute on different CPUs. Therefore, state relating to the execution of these threads must be consistently and correctly marshalled across CPUs.
%	
%	%When these threads resume, they may be executing on different CPUs. The state relating to the execution of those threads must be consistently marshalled across CPUs.
%	
%	%When an instrumented thread of execution on one CPU is re-scheduled to execute on another CPU, 
%	
%	
%	%DRK maintains CPU-private state that tracks the code executing on the . This approach was motivated by performance: DRK rarely contends for shared resources because most resources are not shared. However, managing the consistency of CPU-private state is challenging. For example, state relating to a thread's execution on one CPU must be marshalled to another CPU if that thread is re-scheduled to execute on another CPU.
%	
%	%because a thread of execution can be abitrarily interrupted and resumed on a different CPU. 
%	
%	%The complexities of managing the existing state increased when we modified DRK to frequently take and relinquish control of excution. For example, our modified DRK once ``got lost'' because uncleared state on one CPU caused some unrelated code to redirect its execution to recently interrupted code.
%	
%	DRK's approach to state management made creating tools that alter how they instrument code very challenging. These challenges motivated the creation of policy-driven instrumentation in Granary. Policy-driven instrumentation manages state in a way that is resilient against arbitrary pre-emption/resumption and that allows a tool to dynamically alter how code is instrumented. The value of this approach is that it simplifies the process of creating flexible and dynamic instrumentation tools that run in OS kernels.
%	
%	%a new approach of managing state that is resilient against arbitrary pre-emption and resumption, and enables : \emph{policy-driven instrumentation}.
%	
%	%of a failure to clear some state resulted in interrupted code being linked to unrelated code, resulting in  control flow paths.
%	
%	%of the interaction of interrupt-handling, state-management, and patching of translated code. 
%	
%	%Performance-centric instrumentation systems (e.g. DR and by extension, DRK) are hard to extend and debug. 
%	
%	%Originally, we extended DRK to instrument only modules and ``detach'' when kernel code is executed. We faced many hard-to-debug problems related to how DRK maintains state about what is being instrumented/executed. Sometimes, our modified DRK would ``get lost'' because of the interaction of interrupt-handling, state-management, and patching of translated code. We observed that maintaining more information within generated code about what that code is/does benefits debugging and tooling, perhaps to the detriment of raw performance.
%	
%	\paragraph{Transparency} DRK inherits its strict transparency model from DynamoRIO: the presence of DRK should not alter the behaviour of the kernel or its modules. Our experience with instrumenting the kernel and its modules is that maintaining strict transparency requires sacrificing flexibility and is often unnecessary.  This motivated the adoption of a relaxed transparency model in Granary, which enables efficient mixed-mode execution.
%	
%	Mixed-mode execution is the ability to arbitrarily take and relinquish control. The benefit of this feature is that tools have the option to run some code without overhead by not instrumenting that code. The value of this feature is that instrumentation tools can target and instrument specific code without negatively affecting overall system performance.  %Granary uses mixed-mode execution to instrument only module code, without imposing overhead to non-module kernel code. 
%	
%	We first implemented transparent mode switching within DRK using hardware page protection. While this approach was satisfactory, it failed to provide our system with useful information about what kinds of module code were being executed by the kernel. However, the relaxed transparency model of Granary enables zero-cost mode switching, reveals which kernel interfaces were used to mode switch, and does not alter module or kernel behaviour.
%
%\fi

%Mixed-mode execution can be implemented transparently using the hardware's page protection mechanisms; however, this approach imposes the overhead of faulting on every mode switch without any benefits above and beyond transparency.


%enables zero-cost mode switching in a way that gives us rich information about which kernel interfaces are used at mode-switch boundaries.

%This insight motivated the design of a 

%transparency can be relaxed in many cases.

%\iffalse
%	\paragraph{Transparency} DRK inherits its strict transparency model from DynamoRIO: the presence of DRK should not alter the behaviour of the kernel or its modules. Our experience with DRK was that the mechanisms for maintaining strict transparency inhibit the creation of interesting instrumentation tools.
%	
%	For example, DRK enforces interrupt transparency in two ways: \begin{enumerate}[i)]
%		\item {\bf Precise interrupt delivery:} interrupts are delivered on native instruction boundaries, even when individual native instructions sometimes correspond to multiple instrumented instructions. If instrumented code is interrupted, then DRK will delay the interrupt until control reaches the next logical instruction boundary.
%		\item {\bf Transparent interrupt stack frames:} if instrumented code is interrupted, then DRK will present the kernel with an interrupt stack frame that looks as though native code was interrupted.
%	\end{enumerate}
%	
%	Combined, these forms of transparency limit tools to adding only idempotent intrumentation. Instrumentation instructions executed during the delay of an interrupt may be re-executed after the kernel handles the interrupt because DRK re-instruments the native code targeted by the interrupt's return address. In this model, one cannot spill/restore registers around a native instruction because the spilling instructions may be abitrarily re-executed while the restoring instructions will execute only once.
%	
%	Our experience has been that the mechanisms needed to enforce strict transparency prohibit flexible instrumentation with no benefit beyond the claim of transparency.
%\fi


%restriction to idempotent instrumentation is prohibitive, and that prov

% previously delayed instructions may be re-executed when an interrupt returns.

%This approach to interrupt transparency presents a contradiction when creating complex instrumentation: instrumentation added by 

%DRK's interrupt transparency presents a contradiction when creating complex instrumentation. DRK attempts to ensure two 

%For example, DRK's interrupt transparency presents a contradiction when creating complex instrumentation. DRK ensures precise interrupt delivery: interrupts are delivered on native instruction boundaries, even when individual native instructions can correspond to multiple instrumented instructions. One motivation for this

%For example, DRK maintains the precise interrupt semantics of x86: interrupts are only delivered on native instruction boundaries. However, a single native instruction can correspond to many instrumented instructions. Therefore, DRK opts to delay interrupts to logical native instruction boundaries. A concern of DRK is that some memory operations may alter the hardware interrupt delivery state. However, some instrumentation, in order to be transparent, \emph{must} 

%instrumented instructions might represent fractional native instructions.


%However, strict transparency restricts the mechanisms of implementing attaching and detaching.

%Originally, we implemented attaching and detaching using page protection: our modified DRK would take control of execution if/when an attempt to execute page-protected module code raised a fault. However, this approach left us with very little information about the interfaces used by the kernel to invoke the module.

%when the kernel would invoke module code, the processor would fault, and our modified DRK would take control and instrument the module code. We were able to successfully attach and detach; however, we learned nothing about \emph{what} module code the kernel was calling: 


%we found that the only way to reliably detach instrumentation when module code invokes kernel code, while still being able to reliably re-attach at the correct time, was to relax this transparency model. 
%\iffalse
%	\paragraph{High-Level Information} DRK encourages the creation of tools that instrument the kernel and its modules by manipulating individual binary instructions. However, this focus ignores a bigger picture: developing analysis tools requires understanding how modules and the kernel behave.  This concern motivated the design of reifying instrumentation in Granary.
%	
%	Reifying instrumentation uses information derived from statically analysing the kernel's source code to provide contextual information to instrumentation tools. Reifying instrumentation allows tools to inspect and manipulate program memory at mode switch boundaries in a well-defined way. This is useful because it helps instrumentation tools learn more about the execution of otherwise opaque module binaries. This is valuable because Granary tools can perform the same low-level manipulations of module binaries, but with the guidance of high-level information.
%\fi
%Creating tools that reason about arbitrary, binary kernel modules requires having a deep understanding of how modules and the kernel interact.


%It is difficult to create tools that reason about abitrary, binary modules without incorporating available information present in the kernel's source code. This motivated the 

%However, DRK lacks a way of incorporating static program information into its instrumentation process. This was disappointing because the kernel's source code is available and contains the

%Our experience with writing memory and control-flow interposition tools for the kernel and its modules has been that transparency 

%Our experience thus far has been that module behaviour is not sensitive to certain 
%\end{enumerate}

%If module source code is unavailable then static analysis of module binaries can range from being a chore (e.g. optimised binaries stripped of debugging information) to being intractible (e.g. indirect control-flow that jumps into the middle of variable-length instructios). Regardless of if module source code is available, static analysis is challenging because of the tight interaction between the module and the kernel.

%Dynamic analysis of kernel modules is challenging because existing tools are either too coarse grained (TODO CITE: DRK, PinOS, QEMU, KVM) or are optimised for performance at the cost of expresive/flexible tooling.


%Static analysis of module source code is difficult because of the tight interaction between modules and the kernel. Some modules, however, are only distributed in a binary format, which makes static analysis intractable. 

\comment{!!!This might narrow the usefulnesss of Granary down by making it seem like we're only useful where static analysis fails, or like we're only useful when source code is unavailable.!!!}

%\iffalse
%	\subsection{Novelties}
%	
%	%was that pre-existing tools were insufficient to 
%	
%	%, regardless of the presence of source code, tools designed with performance as 
%	
%	%We created Granary to address the challenges of module analysis. 
%	
%	
%	%While developing kernel and module analysis tools using the DynamoRIO Kernel (DRK) instrument
%	
%	
%	
%	%Granary is a new dynamic binary translation (DBT) framework created to instrument the Linux kernel and its modules. Granary's key novelties are:
%	%\begin{inparaenum}[i)]
%	%	\item its ability to dynamically change how code is instrumented, called \emph{policy-driven instrumentation};
%	%	\item its ability to maintain control while switching between native and instrumented code, called \emph{mixed-mode execution}; and
%	%	\item its ability to tie static program information lost through compilation back into a program binary, called \emph{reifying instrumentation}.
%	%\end{inparaenum}
%	
%	\paragraph{Policy-driven instrumentation} allows tools to specify how to instrument code running in different contexts. In Granary, instrumentation policies are the preferred mechanism for tracking and propagating state concerning the system's awareness of the code being instrumented. For example, Granary records whether or not an execution of some code is within the context of a usage of a SIMD register. The majority of code \comment{!!!Double check me!!!} does not use SIMD registers, which allows Granary to aggressively optimise its execution by avoiding the unnecessary overhead of saving/restoring the SIMD registers on most control transfers to/from Granary. This is an example of a more general pattern within Granary: instrumentation policies are used to implement and switch between multiple ``levels'' or ``weights'' of instrumentation, each with their own performance and runtime characteristics.
%	
%	%of how Granary can be used to implement different ``weights'' of instrumentation as a means 
%	%Policies are also used to switch between different ``weights'' of instrumentation. For example, 
%	 %up until some condition (context-, control-, or data-specific) is true, null instrumentation is used for eff
%	%Inside of Granary tools, policies are often used to support multiple ``levels" or ``weights" of instrumentation: null\comment{!!!Define nomenclature!!!} instrumentation is applied until a condition (context-, control-, or data-specific) triggers a switch to a different policy that performs a more heavyweight analysis of program behaviour.
%	
%	\paragraph{Mixed-mode execution} allows Granary to efficiently switch between native (uninstrumented) and instrumented code at well-defined \emph{detach} and \emph{attach} points. The benefit of this feature is that tools have the option to run some code without overhead by not instrumenting that code. The value of this feature is that instrumentation tools can target and instrument specific code without negatively affecting overall system performance.\comment{!!!Qualify me!!!} Granary implements mixed-mode execution by relinquishing control at detach points and (efficiently) regaining control at attach points. This makes Granary \emph{comprehensive}: it controls/instruments all execution of any code of interest.
%	
%	\paragraph{Reifying instrumentation} is the process of using static program information known at mode-switch boundaries to guide the application of different instrumentation policies. Reifying instrumentation allows tools to inspect and manipulate a portion of program memory at attach and detach points and in a well-defined way. This is useful because it helps the instrumentation system learn more about the execution of an otherwise opaque binary. The value of this feature is that users can create low-level instrumentation tools that operate on programs in a high-level way. The key insight of reifying instrumentation is that even arbitrary binaries must follow conventions and APIs to correctly interact with other programs.
%	
%	Reifying instrumentation enables optimisations as well. Internally, Granary uses this feature to implement zero-overhead mode-switching between native kernel and instrumented module code.
%
%\fi

%, as well as using this information to learn more about the execution of an otherwise opaque binary. 

\subsection{Goals}\label{sec:goals}

Our goal when creating Granary was to make a flexible and efficient framework that developers can use to create tools that analyse arbitrary, binary modules. In pursuit of this goal, we designed Granary so that its tools would be \begin{inparaenum}[i)]
	\item easy to prototype;
	\item easy to debug;
	\item portable;
	\item comprehensive; and
	\item efficient.
\end{inparaenum}


%While designing Granary, we identified the following five features that help achieve this goal: testability, debuggability, portability, comprehensiveness, and efficiency.

\paragraph{Easy to prototype:} Creating instrumentation tools that run in pre-emptive kernels on multi-core computers is challenging. Our experience is that, when possible, modelling a kernel space problem and its instrumentation in user space allows tool developers to easily test assumptions and gain insights. Therefore, we designed Granary to be also able to instrument user space code on both Linux and Mac OS X. We have found this feature very useful as a way of weeding out bugs in new instrumentation tools before applying those tools to actual kernel modules.

%We have found that testing tools in user space has the benefit of quicker turn-around time when making changes, and that the plethora of user space debugging tools enables faster.

\paragraph{Easy to debug:} Debugging tools that transform and generate executable code on-the-fly can be challenging. However, Granary ameliorates the experience by providing rich debugger commands that query structured meta-data stored alongside all generated code. For example, Granary facilitates debugging by allowing a debugger to step back in time over recently executed basic blocks, inspect/query the register state on entry to those basic blocks, and see what instrumentation policies/state was used to create those basic blocks.

%, Granary maintains structured meta-data along with all generated executable code. Meta-data is queried by \texttt{gdb} debugger commands to provide rich debugging information.

\paragraph{Portable:} The Linux kernel and its modules have many different versions, including several long-term support  versions. To support the development of module debugging tools for discovering bugs that appear on only some kernel versions, Granary was designed to be portable across several kernel versions and compiler toolchains.

Granary runs on any of Linux 2.32.x to Linux 3.9.x, compiles with both \texttt{gcc} and \texttt{clang}, and requires no changes to the kernel's source code. Granary also runs in user space on Linux and Mac OS X.

\paragraph{Comprehensive:} Granary is comprehensive in two ways. First, if code is meant to be instrumented then it always executes under Granary's control. Second, Granary does not depend on hardware virtualisation or module source code. This enables Granary to instrument any binary kernel module.

\paragraph{Efficient:} Mixed-mode execution enables some code to run without overhead by executing that code natively. When instrumenting Linux kernel modules, Granary imposes no performance overheads on non-module kernel code.


\subsection{Contributions}\label{sec:contrib}

Our contributions are described in the following sections:
\begin{enumerate}[i)]
	%\item The design and implementation of three novel instrumentation techniques: policy-driven instrumentation, mixed-mode execution, and reifying instrumentation.
	\item In \Cref{sec:policies}, we discuss a new approach to maintaining and propagating state within a DBT system through the use of instrumentation policies.
	\item In \Cref{sec:modes}, we discuss how to implement a DBT system that is designed to frequently relinquish and regain control, while still being comprehensive. Our approach uses active and passive methods that detect and interpose on potential mode-switch boundaries.
	\item In \Cref{sec:reify}, we discuss a new approach of unifying static and dynamic instrumentation. \comment{!!!CUT THIS BECAUSE IT BORES SYSTEMS REVIEWERS?!!!}Our approach uses static type and semantic program information known at mode switch boundaries to guide instrumentation.

%a mixed-mode instrumentation through the use of static program analysis and code generation, and 
% policy-driven instrumentation. This approach enables a DBT system to dynamically change how code is instrumented without having to worry about maintaining the consistency of any runtime state.
	\item In \Cref{sec:env}, we discuss some of the challenges of kernel-space instrumentation, as well as some of the benefits inherent to  the environment.
	\item In \Cref{sec:interrupts}, we depart from previous kernel-space instrumentation work and discuss a new approach to handling hardware and software interrupts occuring within translated code.
\end{enumerate}

\section{Instrumentation Policies}\label{sec:policies}

New module analysis tools are created by implementing one or more interacting instrumentation policies. Module analysis tools use policies to track state (called \emph{policy properties}) and decide how to instrument code.

Policies also serve a broader role in Granary itself. Granary maintains internal policy properties to optimise its performance and to track certain kinds of control flow. One example of a policy property used by Granary to optimise its user space performance is SIMD register tracking. When Granary detects the usage of a SIMD register, it sets the associated property. This property is inherited through the call chain, and informs Granary on whether or not the SIMD registers must be saved/restored when instrumented code yields to Granary. We say that an execution of a function $F$ is in the context of a usage of a SIMD register when the SIMD property is set. If $F$ is later executed by instrumented code where the SIMD property is not set, then a second instrumented version of $F$ (absent the SIMD property) will be stored in the code cache.

A developer prototyping a module analysis tool that uses multiple policies will automatically benefit from Granary's SIMD-tracking optimisation. Properties apply equally to all policies, and are inherited if/when a control-flow transfer effects a policy switch. However, not every control-flow transferring instruction (CTI) can explicitly change the policy used to instrument code: policies and their properties are not inherited across function returns. The motivation for this asymmetry is that conditions (e.g. SIMD register usage) present in a function $F$ might not be present in $F$'s caller. Because of this, function returns act as a natural mechanism for restoring instrumentation to a previous context. For example, Granary's SIMD register tracking is an effective optimisation because it limits the scope of saving/restoring the SIMD registers to only those yields performed in the context of a SIMD register, and not to all yields performed after the first usage of a SIMD register.

%.... set properties / properties naturally revert / etc. explain why no inheritance through RETs.

%This example of policy properties highlights some of their features: properties are inherited through control-flow instructions, even when policies themselves might change.

%Instrumentation policies are used to create new instrumentation tools and track state for those tools. An instrumentation policy is a set of functions that operate on a sequence of instructions ending in a non-call control-transfer instruction (CTI), called a basic block. The functions of a policy are responsible for adding instrumentation to a basic block and deciding what policy to apply to subsequent basic blocks. Granary is responsible for tracking and propagating any state associated with policies, called \emph{policy properties}.
%	
%	%State is tracked and propagated through the use of policy properties.
%	
%	%The functions of an instrumentation policy can arbitrarily manipulate the instructions of an instrumented program, as well as decide the ``next'' policy should be
%	
%	%Instrumentation policies are the means by which users of Granary can create instrumentation tools, as well as being the preferred mechanism for tracking and propagating state concerning the system's awareness of the code being instrumented.
%	
%	%Instrumentation policies in Granary serve two main purposes:
%	%\begin{inparaenum}[i)]
%	%	\item deciding how to instrument a sequence of instructions; and
%	%	\item tracking and propagating state/context using \emph{policy properties}.
%	%\end{inparaenum}

\subsection{Creating Tools with Policies}

Tool developers must implement three functions for each policy: \begin{enumerate*}
	\item one that instruments a basic block of module code.
	\item one that instruments a basic block of kernel code.
	\item one that handles an interrupt in instrumented code.
\end{enumerate*}

The majority of tools will focus on implementing (1); however, we have found (2) useful when implementing \emph{data-driven instrumentation} and (3) useful when implementing multiple weights of instrumentation in response to interrupt behaviour. 

For example, tools built with Granary's behavioural watchpoints framework expose tainted memory addresses to instrumented modules. Modules and the kernel freely share data, making it almost inevitable for  tainted addresses to ``leak'' into the kernel. If the kernel attempts to access the memory referenced by a tainted address then the processor will raise a fault. We handle this fault by applying function (2) to instrument the faulting kernel code using a policy that protects against such faults ($P_{watchpoints}$). Function (3) is also used to optimise the execution of tools using behavioural watchpoints by initially assuming that code will not dereference a tainted address ($P_{null}$) and upgrading to $P_{watchpoints}$ if a fault on a tainted address occurs within a $P_{null}$-instrumented basic block.

% instrument as much or as little of the kernel as they want in response to this fault.

%Instrumentation policies expose three functions: one to instrument module code, one to instrument kernel code, and one to handle an interrupt in instrumented code.

Functions (1) and (2) can abitrarily manipulate instructions and policy properties before they are packaged into basic blocks. These functions decide what the ``next'' policy should be for each CTI within the basic block. For example, if $P_1$'s function (1) sets the policy of a CTI in the basic block to policy $P_2$, then any module code targeted by the changed CTI will be translated and instrumented by $P_2$'s function (1). 

%Because Granary depends on DynamoRIO's instruction encoder/decoder, the full range of DynamoRIO instruction/operand manipulation functions can be applied to instructions within a basic block.

\subsection{Managing State with Policies}

Policy properties encode state. A policy property describes an aspect of the environment in which the instructions of a basic block execute. Properties are tested, set, and unset by Granary and tool-specific policies over the course of decoding, instrumenting, and packaging instructions into basic blocks. By default, properties are propagated across all control-flow transfers except for return instructions. Property propagation through function call instructions enables inheritance of contextual information through the function call chain. The lack of propagation through function returns enables execution to return to a previous context.

Granary encodes policy information into the meta-data and CTIs of basic blocks. When an instrumented CTI executes for the first time, it yields control to Granary with the CTI target and policy information as inputs. Granary decodes and instruments the targeted instructions according to the input policy information. Granary depends on these inputs alone as a means of ensuring consistency: Granary cannot ``lose track'' of state concerning the execution of some code because the code itself maintains that state. This enables arbitrary pre-emption and resumption of instrumented code without negatively affecting how as-of-yet uninstrumented code will be instrumented. The value of this approach is that it simplifies the process of creating instrumentation tools that run in OS kernels.



%A property is set when Granary detects the usage of a SIMD register. This property is inherited through through the call chain.

%  The latter property is used by Granary to decide how to handle interrupts within instrumented kernel code.

%Instrumentated code can be arbitrarily pre-empted and resumed without concer.

%instrumented code yields control to Granary to build further basic blocks

%Granary was designed to operate in a multi-threaded, multi-core, pre-emptive kernel.

%Policy properties are encoded into the control-transfer instructions and meta-data of each basic block. This ensures that once emitted, the policy information of a basic block is immutable. 

%This is beneficial because Granary behaves in a purely functional way with respect to policies: 

%to be \emph{pure} with respect to policies: Granary's behaviour is fully-determined by 

%Policy properties are eventually immutable because they are directly encoded into the instructions and meta-data once 

%Policy properties are eventually immutable because once instructions have been packaged into a basic block, the properties that determined how those instructions, as well as any instructions targeted by control-transfer instructions within the basic block, were translated/instrumented never changes. 

%Immutability has the benefit of simplifying consistency when running in 

%that are tested, set, and unset by Granary and its policies during basic block creation.

%\paragraph{Policy behaviours}

%\paragraph{Policy conversions} can occur at any control-transfer instruction, with the exception of return instructions.



%If instrumentation purposefully exposes addresses that generate faults when accessed, then a policy interrupt handler can patch the original basic block to re-route control to a version of the original basic basic block that will guard itself against faults on memory accesses. This technique is used by Granary to optimise applications using \emph{behavioural watchpoints} to do fine-grained memory access instrumentation.

% TODO interrupts
%An example of how multiple policies are 

%Changing the policy during execution is useful for 

%\subsection{Clients}

%An instrumentation policy is a mechanism for deciding how to instrument a sequence of instructions, as well as how to instrument instructions targeted by any control-flow transferring instructions within the sequence.

%is a mechanism for maintaining and propagating immutable state that is used to decide how to instrument a sequence of instructions.

%is a mechanism for deciding how to instrument a sequence of instructions based on

% maintaining and propagating immutable state within a DBT system.

%and propagating state, as well as deciding how to instrument a sequence of instructions.

%\section{Managing State}\label{sec:state}
%Granary manages state using three mechanisms: shared data, CPU-private data, and instrumentation policies. 

%\paragraph{Shared data:} Granary maintains a centralised cache of all instrumented code, called the \emph{code cache}. The code cache is a data store that maps native (uninstrumented) code addresses to sequences of instrumented instructions, stored in the form of \emph{basic blocks} and their meta-data. 

%In Granary, a basic block is a maximal sequence of instructions that end in a non-function-call control-flow instruction. The inclusion of function calls within basic blocks is deliberate: Granary operates using a relaxed transparency model, and including function calls is a natural optimisation opportunity given this model. Addresses into the code cache are ``leaked'' to instrumented programs in the form of return addresses saved on the run-time call stack. Code cache addresses also leak to native code when mixed-mode execution is employed. Our experience with kernel instrumentation is that the kernel is not sensitive to such leaks. We have not yet encountered 

%\paragraph{CPU-private data:} Each core maintains a private mapping of native code addresses to code cache code addresses. This mapping

%When a new basic block is translated and stored in the global code cache, the mapping between the basic block and the nativ

%\paragraph{Instrumentation policies:}

\section{Mixed-Mode Execution}\label{sec:modes}
Granary enables instrumentation tools to blah blah blah.

\section{Reifying Instrumentation}\label{sec:reify}

\section{Environment}\label{sec:env}

\subsection{Interrupts and Exceptions}\label{sec:interrupts}

\section{Evaluation}\label{sec:eval}

\section{Related Work}\label{sec:related}

\section{Conclusion}\label{sec:conclusion}

TODO
%\section{}\label{sec:

%\section{Architecture and Design}\label{sec:arch}

%In this section, we describe how Granary meets the goals laid out in \Cref{sec:goals}. To do so, we describe several challenges, alternative approaches, and the solutions we chose.

%Non-module kernel code executes without overhead when Granary instruments kernel modules using mixed-mode instrumentation.

%. First, if a module's code is meant to be instrumented, 

%, both with respect to ensuring that no module code escapes instrumentation, and 

%The environment in which the kernel and its modules execute introduces 
%Often the environment in which kernel and module code executes obfuscates the 
% and the Linux kernel and its modules execute in a complex and dynamic environment. To ease development of new tools, Granary was designed to instrument user space programs in Linux and Mac OS X.
% to have zero overhead, while also allowing further type, policy, and argument manipulation at the point when Granary regains control.
%Granary enables users to interpose on and alter the behaviour 
%at mode-switch boundaries  in a type-safe way
%propagating this information deeper into an otherwise opaque binary.
%of using static program information (type information, semantic information) to guide the choice of which instrumentation policy to apply at attach points, as well as to propagating this information from attach and detach points into an otherwise opaque binary.
%Mixed-mode execution is challenging to implement because Granary is \emph{comprehensive}: the execution of any code of interest is always controlled by Granary. 
%A DBT system is \emph{comprehensive} if it controls/instruments all execution of any code of interest. 
%Mixed-mode execution is challenging to implement because Granary must relinquish its control at a detach point, but (efficiently) regain control at an attach point.
%Mixed-mode execution is challenging to implement because it requires that a DBT system relinquishes its control at a detach point, but has a mechanism to (efficiently) regain control at an attach point. If a DBT system can ensure that it controls/instruments all code of interest, then it is \emph{comprehensive}. Granary solves the problem of comprehensiveness in the face of mode switches using three techniques: static wrappers, dynamic wrappers, and page protection.
%Mixed-mode execution is implemented by relinquishing control at detach points, and regaining control at attach points. The key challenge of implementing mixed-mode execution is how to (efficiently) regain control once it has been relinquished. If a DBT system can ensure that it controls/instruments all code of interest, then it is \emph{comprehensive}. Granary solves the problem of comprehensiveness in the face of mode switches using a combination of \emph{static wrappers}, \emph{dynamic wrappers}, and page protection.
%If a DBT system ensures that all code of interest is instrumented
%users are not required to pay the overhead of the DBT system on code that they are not interested in instrumenting. 
%However, implementing mixed-mode execution is challenging. If a DBT system relinquishes its control over a program's execution, then there is no guarantee that the DBT system will regain control before code to be instrumented is next executed. A DBT system is \emph{comprehensive} if it ensures that all code of interest is instrumented, regardless of if execution control is relinquished. Granary solves the problem of comprehensiveness in the face of mode switches using a combination of \emph{static wrappers}, \emph{dynamic wrappers}, and page protection.
%---in order to comprehensively instrument code of interest (e.g. a kernel module)---Granary must have a mechanism of regaining control even when a mode-switch from instrumented to native code \emph{relinquishes} its control.
%The key challenge of implementing mixed-mode execution is that of \emph{comprehensiveness} in the face of losing control. For example, Linux kernel module code ...
%The motivation for mixed-mode instrumentation is that a user should only have to pay the overhead of instrumenting code of interest. 
%The motivation for mixed-mode instrumentation is that one should only have to pay the cost of instrumentation for the code that one wants to instrument.
%focus on instrumenting that code which they care about.
%when to save those registers lest Granary accidentally clobber those registers and change the instrumented program's behaviour.
%Granary was originally developed as an extension to the DynamoRIO Kernel (DRK) \cite{Feiner2012} DBT framework; however, due to 
%While designing Granary, we identified four goals for efficient kernel instrumentation:
%\begin{enumerate}
%	\item {\bf Efficiency:} 
%\end{enumerate}
%Granary's key novelty is its pervasive support for \emph{mixed-mode execution}: the ability to switch between native and instrumented code on the fly. 
%, which allows users to focus on instrumenting 
%Due to its support for mixed-mode execution, Granary supports multiple granularities of instrumentation: function-, module-, kernel-, data-, and context-specific.
%Granary's key novelty is its ability to instrument a program at multiple granularities.
%\begin{itemize}
%	\item {\bf Function-specific:}
%	\item {\bf Module-specific:}
%	\item {\bf Kernel-specific:}
%	\item {\bf Data-specific:}
%	\item {\bf Context-specific:}
%\end{itemize}
%\section{Design}
%\subsection{Goals}
%Granary was originally designed for analysing Linux kernel modules. During Granary's design, we identified the following four goals: 
%\begin{enumerate}
%	\item[i)] Comprehensively analyse \emph{all} kernel modules.
%	\item[ii)] Impose no performance overheads on non-module kernel code.
%	\item[iii)] Require no changes to modules and minimal changes to the kernel.
%	\item[iv)] Be easily portable between different hardware and kernel versions.
%\end{enumerate}
%Prior work based on source code analysis and annotations \cite{YMao2011} fails to meet goals (i) and (iii), while work based on special hardware features or virtualization \cite{Xiong2011} fails to meet goals (i) and (iv), and work based on whole-OS or -system instrumentation/emulation \cite{Feiner2012} fails to meet goal (ii).
%\subsection{Mixed-mode Execution}
%Executing code belongs to one of three contexts:
%\begin{enumerate}
%	\item {\bf Host}: \texttt{libc} in user space, and the Linux kernel in kernel space. By default, code from this context executes at full speed and without interference from Granary. However, host code is sometimes instrumented depending on the configuration of the active \emph{instrumentation policies}.
%	\item {\bf Application}: Non-\texttt{libc} code in user space, and kernel modules in kernel space. By default, code from this context is instrumented according to one or more \emph{instrumentation policies}.
%	\item {\bf Granary}: Granary's runtime system manages host and application code.
%\end{enumerate}
%Granary is responsible for ensuring comprehensiveness with respect to an execution context. For example, if Granary is configured to instrument a particular kernel module, then Granary ensures that the execution....


\bibliographystyle{acm}
\bibliography{library}
\end{document}
