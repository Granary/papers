\documentclass[preprint]{sigplanconf}
\usepackage{cleveref,amsmath,chngcntr}
\usepackage{textcomp} % for tilde
\usepackage{paralist} % for in-paragraph lists
\usepackage{url}
\usepackage{graphicx}
\usepackage{multicol}

% For drawing FSMs
%\usepackage{tikz}
%\usetikzlibrary{arrows,automata}

% Used for code snippets
\usepackage{listings,courier}
\usepackage{subfig,epsfig}
\DeclareCaptionType{copyrightbox}
\usepackage{epsfig}


% Settings on code listings.
\lstset{language=C,
		xleftmargin=0pt,
		xrightmargin=0pt,
		framexbottommargin=0pt,
        framextopmargin=0pt,
        framesep=0pt}
\usepackage{enumitem}

% Add listing language for assembly
\lstdefinelanguage
   [x64]{Assembler}     % add a "x64" dialect of Assembler
   [x86masm]{Assembler} % based on the "x86masm" dialect
   % with these extra keywords:
   {morekeywords={CDQE,CQO,CMPSQ,CMPXCHG16B,JRCXZ,LODSQ,MOVSXD, %
                  POPFQ,PUSHFQ,SCASQ,STOSQ,IRETQ,RDTSCP,SWAPGS, %
                  rax,rdx,rcx,rbx,rsi,rdi,rsp,rbp, %
                  r8,r8d,r8w,r8b,r9,r9d,r9w,r9b}} % etc.

% For leaving some comments in the draft.
\newcommand{\comment}[1]{}

% Customize cleverref
\crefname{section}{Section}{Sections}

\begin{document}

%make title bold and 14 pt font (Latex default is non-bold, 16 pt)
\title{Flexible Binary Instrumentation for the Kernel}

%for single author (just remove % characters)
\authorinfo{Peter Goodman \and Akshay Kumar \and Angela Demke Brown \and Ashvin Goel}
{University of Toronto}{}
% end authorinfo

\maketitle
\subsection*{Abstract}
%Kernel modules extend the functionality of operating systems. They represent the bulk of new kernel code in development and contain the majority of new kernel bugs. Unfortunately, analyzing and debugging modules is very challenging. Static analysis of module source code is difficult because of the tight interaction between modules and the kernel. Some modules, however, are only distributed in a binary format, which makes static analysis intractable. Existing dynamic analysis tools capable of instrumenting modules are not suited toward module analysis. They either impose unnecessary performance overheads, lack flexibility and are too coarse-grained, or do not provide a means of understanding the ``big picture'' view of what an arbitrary module does as it executes.

%We created Granary to address the challenges of module analysis. Granary is a framework for creating flexible and efficient tools that analyze or debug arbitrary, binary Linux kernel modules. Granary uses dynamic binary translation to dynamically rewrite and comprehensively instrument kernel modules. Granary makes it easy to create flexible tools by supporting context-aware runtime code specialization, and by integrating high-level static analysis information with low-level instruction manipulation. Module analysis tools built on Granary are efficient because of Granary's adoption of a relaxed transparency model, and because of Granary's ability to instrument module code without imposing overhead on non-module kernel code.


\section{Introduction}\label{sec:intro}

Granary is a framework for creating flexible and efficient tools that instrument the Linux kernel. Granary's key novelty is its \emph{runtime code specialization} feature, which enables tools to decide what code to instrument, and how to instrument that code. Flexible specialization allows tools to be picky about instrumentation. For example, a tool can choose to instrument every load and store operation, but only inside nested critical sections that are executing in module code. Granary's runtime code specialization feature addresses two limitations of existing kernel analysis systems: \begin{inparaenum}[i)]
	\item they have focused on instrumenting all code \cite{DRK,btkernel,QEMU}; and
	\item they can only instrument code using a single policy.
\end{inparaenum}

%Operating system (OS) kernels present an apparently insane environment for a transparent binary instrumentation framework.  For example, hardware interrupts can redirect control flow at any instruction, and interrupt delivery cannot be delayed past the execution of memory instructions that might alter the interrupt delivery state~\cite{DRK}. Preserving interrupt transparency, however, requires that interrupts be delayed until the end of any injected instrumentation instructions.  Together, these requirements make it very difficult to write instrumentation tools.  The insane environment of OS kernels also creates several opportunities for analysis tools. For example, interrupts can be ``tamed'' and put to new uses; privileged hardware features can be used; and the kernel ABI and source code can be relied upon to be a good predictor of module behavior at the kernel/module boundary. We also found that the kernel is largely insensitive to transparency issues, allowing us to relax transparency in exchange for both improved performance and greater visibility into the execution of instrumented code.  This increased visibility is particularly important for analysis and debugging tools.

%The challenges and opportunities of the kernel environment motivated the creation of Granary. Granary is a new binary instrumentation framework for the Linux kernel environment, designed specifically for analyzing kernel modules. Granary targets modules because they represent the bulk of new bugs and new code in development in the Linux kernel \cite{FaultsInLinux}. Granary allows developers to create flexible and dynamic analysis tools for arbitrary Linux kernel module binaries. Granary has two main goals: \begin{inparaenum}[i)]
%	\item make it easy to create efficient, low-level analysis tools; and
%	\item provide high-level static analysis information to the analysis tools.
%\end{inparaenum} Granary achieves the first goal by using dynamic binary translation (DBT) to provide low-level access to instructions, memory, and interrupts. Granary achieves the second goal by giving tools direct access to the results of its own static analysis of the Linux kernel source code. By meeting these goals, Granary tools are able to do things like  figure out which data structure fields are associated with each memory access.

%Granary addresses three limitations of existing program analysis systems: \begin{inparaenum}[i)]
%	\item they have focused on instrumenting all code \cite{DRK,btkernel,QEMU};
%	\item they do not allow for flexible runtime code specialization; and
%	\item they do not provide static type information to the instrumented code.
%\end{inparaenum} 

Instrumenting all code (e.g., the whole kernel) imposes unnecessary performance overheads when only a subset of the code is being analyzed (e.g., modules, functions). In practice, we would like to target instrumentation at specific code for efficiency, while also allowing rich and detailed instrumentation of the targeted code. This requirement motivates the design of \emph{mixed-mode execution}, which allows Granary tools to instrument only specific code while the majority of code executes with zero overhead. 

%This is challenging because Granary must be comprehensive: all code that is meant to be instrumented should be instrumented. In other words, relinquishing control to execute kernel code natively must not cause Granary to miss the execution of any module code.

Another limitation of existing systems is that they are unable to perform efficient runtime code specialization, i.e. they are unable to change how code is instrumented based on the context in which that code will run. For example, Granary's Read-Copy-Update (RCU) debugging tool, \texttt{RCUdbg}, specializes instrumentation at different stages of use of the RCU synchronization API. Correct usage of the RCU API allows programmers to create scalable, shared data structures that permit concurrent access and modification. The ``trick" of RCU is that readers might not see the latest write to the data structure, and writers must synchronize to modify the data structure. \texttt{RCUdbg} distinguishes between code executing inside \emph{read-side} and \emph{write-side} critical sections, and instruments each code context differently. In read-side critical sections, \texttt{RCUdbg} detects bugs when readers access potentially non-existent data, do not the correct accessor API, or attempt to write to shared data. In write-side critical sections, \texttt{RCUdbg} detects when writers write to shared data without using the correct API. 

%is a synchronization mechanism that permits readers to operate concurrently with writers, but does not guarantee that readers observe the most up-to-date changes (by writers) to shared state.  RCU readers 

%When used correctly, RCU readers must declare that they will operate on shared state by entering into a read-side critical section, delimited by \texttt{rcu\_read\_lock} and \texttt{rcu\_read\_unlock}, respectively. When inside a read-side critical section, a pointer to shared state \emph{must} be obtained by invoking \texttt{rcu\_dereference}. Thereafter, a reader can freely access the shared state through this pointer, but only up until the 

%In reader-side code

%For example, Granary has a tool that  dynamically constructs inter- and intra-procedural control flow graphs (CFGs). The outputs of this tool enable Granary to do better runtime register allocation, which improves tool efficiency. Part of building CFGs requires tracking whether or not a given basic block is the entrypoint to a function. This is challenging with existing DBT systems because some optimised functions will re-execute their first basic block, which might incorrectly appear as new function calls in the CFGs. Granary solves this problem using demand-based runtime code specialization: every entrypoint basic block is instrumented in one way, and later re-executions of any entrypoint basic blocks are specialized and instrumented in another way.

The \texttt{RCUdbg} tool is an example of \emph{context-driven code specialization}: code executing inside of a read-side critical section is instrumented differently from code executing inside of a write-side critical section, and code execution outside of both contexts executes with minimal instrumentation. In a Granary tool, each tracked execution context is associated with its own instrumentation policy. An instrumentation policy decides how to instrument code that will execute within the associated context. Granary is able to track execution contexts because it explicitly maintains policy information in translated basic blocks. This avoids typical poblems with tracking context in just-in-time DBT systems (e.g., maintaining runtime context-tracking state, reentrancy, and the inability to predict later execution contexts at translation time).

% In the previous example, executing code is classified into two contexts: entrypoint and non-entrypoint basic blocks.  In the case of our CFG tool, two policies track the two execution contexts: $P_{\mathit{call\_entry}}$ and $P_{\mathit{after\_entry}}$. $P_{\mathit{call\_entry}}$ applies to the first execution of the first basic block of each function, and connects functions in the inter-procedural CFG.  $P_{\mathit{after\_entry}}$ applies to all other executed basic blocks within each function, including re-executions of the first basic block. $P_{\mathit{after\_entry}}$ connects basic blocks in the intra-procedural CFG. 

%Finally, an important missing feature of existing low-level instrumentation systems is the ``big picture'' view that one gets from static analysis information. Similarly, static analysis tools lack access to instructions, memory, and processor-specific behaviors that are only available to low-level runtime instrumentation tools. Existing mixed static/dynamic analysis tools \cite{NaCl,AddressSanitizer,ThreadSanitizer} appear to get the best of both worlds, but sacrifice on runtime flexibility by committing to a single instrumentation policy at a program's compile time. The benefits of high-level static analysis motivated its inclusion into Granary using a technique we call \emph{reifying instrumentation}. Granary statically analyzes the Linux kernel source code to bootstrap learning about  the interfaces that enable modules and the kernel to interact. Granary exposes this information to instrumentation tools in the form of type and function \emph{wrappers}. Tools can use wrappers to apply context-specific policies when instrumenting module code as well as to inspect and manipulate parts of kernel/module memory in a type-safe way.

%For example, we are actively developing a tool that uses static type information to learn about all the fields of all kernel data structures that are read from or written to by modules. This information allows us to model things like how a typical file system operates on kernel data structures in the process of opening a file. From these models, we can construct behavioral patterns about how modules use kernel data structures and functions. These patterns can be used to classify modules \cite{DeviceDriverClassification} and identify spurious behavior \cite{LXFI}.

The rest of the paper describes Granary in more detail. \Cref{sec:dbt} describes how Granary is implemented. 

% \Cref{sec:modes} describes how to efficiently implement mixed-mode execution. \Cref{sec:policies} describes a new method for dynamically changing how code is instrumented. \Cref{sec:reify} describes how to integrate static analysis information into a DBT system. Finally, \Cref{sec:eval} evaluates Granary's performance.

\section{Dynamic Binary Translation}\label{sec:dbt}

Granary uses dynamic binary translation (DBT) to instrument the Linux kernel. DBT is used for emulation \cite{QEMU}, runtime optimization \cite{DynamoRIOOptimisation}, and runtime instrumentation (analysis \cite{DynamoRIO, DRK, btkernel, ProfilingSimics}, security \cite{Vx32,NaCl,ProgramShepherding}, and debugging \cite{Valgrind}). We chose DBT because \begin{inparaenum}[i)]
	\item static binary analysis tools are unable to cope with \texttt{x86}'s mix of variably-sized instructions and data; 
	\item some kernel code is only distributed in a binary format (e.g. proprietary device drivers); and
	\item virtualization-based approaches are unable to analyze non-virtualizable device drivers \cite{DRK}.
\end{inparaenum}

%Granary translates and instruments code at one of three default granularities: kernel, module, and function (also called probe-based instrumentation). 
%
%At runtime, the granularity of instrumentation can be altered based on the execution context. For example, a tool analyzing modules for bugs can choose not to instrument a particular function (e.g. whitelist the function) if that function is known to not contain bugs, or known to generate many false-positives.
%
%\paragraph{Kernel}
%Granary interposes on the system call and interrupt entrypoints, located in the x86-64 \texttt{MSR\_LSTAR} model-specific register and interrupt descriptor table (IDT), respectively. 
%
%\paragraph{Module}
%
%
%\paragraph{Function}
%
%Granary can interpose on the execution of specific kernel functions in three ways:
%\begin{enumerate}
%	\item {\bf Wrapping:} Granary can substitute the execution of a kernel function when that function is invoked from instrumented code. A different function can be substituted depending on the context from which the original function is invoked (instrumented kernel code, instrumented module code). We call this type of interposition ``wrapping'' because it is commonly used to inspect the substituted function's arguments and return value, while still invoking the original function.
%	\item {\bf Substituting:} Granary can substitutes the execution of a kernel function, even when that function is executed by native kernel code. This is useful when tools only instrument part of the kernel (e.g. modules or functions) but require visibility on specific kernel events happening outside of the instrumented code (e.g. particular memory allocations).
%	\item {\bf Instrumented Wrapping/Substituting:} Granary can optionally instrument wrapped or substituted code. This is useful when tools want to observe function arguments/return values using high-level C/C++ code, but where that function must be instrumented for visibility.
%\end{enumerate}

Granary translates and instruments kernel binaries one basic block at a time. In Granary, a basic block is a sequence of instructions ending in a conditional branch, \texttt{ret}, or \texttt{jmp}, but not a \texttt{call} instruction. Entrypoint basic blocks (e.g. interrupt vectors, system call entrypoints, module initializers) are translated ahead-of-time, and all other basic blocks are translated just-in-time (JIT) as execution ``discovers'' them. Translated basic blocks are linked together and stored in a globally accessible \emph{code cache}.

Granary's just-in-time translation approach means that code executing from the code cache may yield control to Granary to request the address of the next basic block to execute. When instrumented code yields to Granary, a ``context switch'' occurs that transfers execution to a CPU-private stack where Granary operates. Granary context-switches back to the code cache when the next basic block has been found or translated so that instrumented execution may continue. Similar to other DBT systems, Granary uses caching and hot code patching to reduce the number of context switches. In our experience, kernel code stabilizes very quickly: context switches stop happening after the first few seconds of translation.

Basic blocks in Granary's code cache contain x86-64 binary instructions. Associated with each basic block is meta-data describing the instructions of the basic block, and the instrumentation policy used to instrument those instructions. Basic block meta-data includes: \begin{inparaenum}[i)]
	\item the length in bytes of the original and translated basic blocks;
	\item the address of the first instruction in the original basic block; and
	\item the instrumentation policy.
\end{inparaenum} Basic block meta-data is queried and extended by Granary instrumentation tools. For example, Granary's control-flow graph build tool, \texttt{cfg}, extends the basic block meta-data to track per-block execution counts. Block meta-data is also queried by interrupt handlers when deciding how to handle interrupts and exceptions in instrumented code, and by debuggers (e.g., \texttt{gdb}) to give contextual information about a translated basic block. 

\subsection{Transparency}\label{sec:transparency}

An instrumentation system is transparent if, given the same inputs, the instrumented and uninstrumented versions of a program behave in the same way \cite{Transparency}. Granary includes configurable levels of transparency to address the trade-off between transparency and overhead. By default, Granary uses a relaxed transparency model for efficiency, flexibility and increased visibility, but if instrumentation for some module requires transparency then it can be enabled at the cost of increased overheads and decreased visibility. By default, Granary exposes the following two artifacts: code cache addresses as function and interrupt return addresses.

\paragraph{Function return addresses}\label{para:return_address_transparency} Unlike most DBT frameworks, Granary inlines \texttt{call} instructions into basic blocks, which exposes code cache addresses to instrumented module code in the form of return addresses. Inlining \texttt{call} instructions avoids return-address mispredictions and unnecessary control-flow by building longer basic blocks. 

\paragraph{Interrupt return addresses} Kernel interrupts are not sensitive to return addresses and hence relaxing return address transparency has no effect on interrupts. A special case arises for page fault exceptions that occur within specific kernel functions that access user space data \cite{btkernel}. The Linux kernel records ranges of code addresses that are permitted to fault in an ``exception table'' data structure, and on a page fault exception, checks if the interrupt return address belongs to one of the pre-defined ranges. Granary records any exception table entries as part of each basic block's meta-data, so that a page fault in a basic block can be mapped to the correct native faulting program counter.

%\paragraph{Module function wrappers} Granary does not maintain transparency when its type wrappers replace pointers to module functions with pointers to wrapped module functions. This is perhaps the riskiest break in transparency within Granary because a module might treat a function pointer as being representative of the module being in some particular state.\footnote{We have not yet encountered a module where changing pointers to module functions into module wrappers altered the module's behavior under instrumentation.} If Granary is configured to use transparent module function pointer addresses in shared data structures then fast attaching is disabled and tools will not have access to the same level of static program information.

\subsection{Reentrancy}

\paragraph{Code cache}
Granary's code cache and JIT translation mechanism is fully reentrant. Context-switches into Granary disable interrupts and switch execution onto a CPU-private stack. Context switches out of Granary and into the code cache or native code returns executuin to the native stack and re-enables interrupts. JIT translation, however, presents a problem: context-switches save or restore the entire register state, so as not to disturb the execution of the instrumented program. This raises the question: when resolving the target of a direct or indirect control-flow instruction, how should execution be directed to the correct location?

Like btkernel, Granary solves this problem using  by generating ``edge'' code for each direct control-flow instruction (e.g. \texttt{call}, \texttt{jmp}, \texttt{jcc}). When a basic block is first translated, its direct control-flow instructions (CTIs) are converted into jumps to CTI-specific edge code. Edge code lives outside the code cache and is responsible for transferring control from a basic block ($B_{pred}$) to Granary so that the next basic block ($B_{succ}$) can be found/translated, and then connected ($B_{pred} \underset{\texttt{jz}}{\to} B_{succ}$) via hot code patching. Reentrancy of edge code is obtained by spilling registers onto the runtime call stack, and later restoring them before jumping back to the now-patched CTI (\Cref{fig:direct_edge_code}).

Granary also generates edge code for indirect control-flow instructions; however, this edge code is split into two separate components: entry and exit edge code. Entry edge code is generated on a per-indirect CTI instruction basis, and spills registers onto the runtim call stack. Entry edge is responsible for indirect branch lookup, and will indirectly jump to the exit edge code for a given basic block. Exit edge code is generated for each basic block that is targeted by an indirect CTI. Exit edge code restores the register state saved by the entry edge code, and then directly jumps to the beginning of the targeted basic block.

\paragraph{Instrumentation}

% Code block showing an example JZ (jump if ZF=1).
\lstset{language=[x64]Assembler}
\newsavebox\nativejcc
\begin{lrbox}{\nativejcc}
\begin{minipage}[b]{4cm}
\begin{lstlisting}[basicstyle=\footnotesize\ttfamily]
cmp $0x0, %rax
jz value_is_zero 
...
( fall through )
\end{lstlisting}
\end{minipage}
\end{lrbox}

\newsavebox\translatedjcc
\begin{lrbox}{\translatedjcc}
\begin{minipage}[b]{4cm}
\begin{lstlisting}[basicstyle=\footnotesize\ttfamily]
  cmp $0x0, %rax
jz_to_patch:
  jmp edge_value_is_zero
  ...
edge_value_is_zero:
  ( spill 2 registers )
  ( save value_is_zero )
  ( save target policy )
  call patcher_for_jz
  ( restore 2 registers )
  jmp .jz_to_patch
\end{lstlisting}
\end{minipage}
\end{lrbox}

\begin{figure}[t!]
\subfloat[Native Code]{\usebox\nativejcc}
\hfill
 \subfloat[Translated Code]{\usebox\translatedjcc}
\caption{\label{fig:direct_edge_code}Example translation of a conditional control flow instruction (\texttt{jz}) and its edge code. The edge code saves the intended target of the jump (\texttt{value\_is\_zero}) and the instrumentation policy to apply when translating the targeted code, and then context-switches into Granary by invoking \texttt{patcher\_for\_jz}. The \texttt{patcher\_for\_jz} function atomically replaces the {\bf\texttt{ jmp}}\texttt{ edge\_value\_is\_zero} instruction with a fully resolved \texttt{jz} instruction, and upon return, executes the newly resolved \texttt{jz} instruction.}
\end{figure}

One challenge with any DBT system is how it copes with non-reentrant instrumentation. For example, instrumentation that modifies CPU-private data structures cannot be safely executed by pre-emptive kernel running on a multi-core system. If the task being instrumented is interrupted, then the kernel might decide to re-schedule the task to resume its execution on a different CPU. Any modifications to CPU-private state would lead to undefined behavior.

DRK's solution to this problem assumes that all injected instrumentation instructions are potentially non-reentrant, and \emph{delays} interrupts occuring within instrumented code \cite{DRK}. Interrupt delaying allows DRK to maintain the precise interrupt semantics of x86: interrupts only arrive on \emph{logical} instruction boundaries, and kernel interrupt handlers only observe faults or exceptions at native instruction boundaries. This approach introduces subtle complexity when creating instrumentation that injects instructions both before (pre) and after (post) native instructions. For example, an interrupt occuring in the pre-instrumentation of a native instruction will be delayed only until the native instruction. When the interrupt is handled and execution attempts to return to the interrupted instructions, DRK re-instruments the ``tail" of interrupted basic block, starting from the native instruction. Instrumenting this tail involves injecting pre- and post-instrumentation around the first native instruction. If the pre-instrumentation is not idempotent, then its re-execution will result in undefined behavior. We encountered this issue when using DRK for kernel module instrumentation, where our pre-instrumentation spilled registers to the runtime call stack, and our post-instrumentation restored the spilled registers. Because of interrupt delaying, the spilling code was sometimes repeated many times, whereas the restoring was only executed once. This led to hard-to-debug kernel crashes.

Btkernel provides no solution to the problem of handling non-reentrant instrumentation, beyond requiring that instrumentation tools disable and re-enable interrupts around non-reentrant instrumentation code \cite{btkernel}. Unfortunately, disabling and re-enabling interrupt is costly.

Granary charts a middle ground between the two aforementioned approaches. Interrupt delaying has value because it enables non-reentrant instrumentation to be injected without costly disabling/enabling of interrupts, while not supporting delaying has value because not all instrumentation is non-reentrant. By default, Granary does not delay interrupts. However, instrumentation tools can declare \emph{interrupt delay ranges}: sequences of instructions (which can contain internal control flow) inside of a basic block that must be executed atomically. Granary encodes bounds information about interrupt delay ranges inside of each basic block's meta-data. When a basic block is interrupted, Granary inspects the meta-data and determines if the interrupt must be delayed. If a delay is required, then the instructions belonging to the delay range are copied into a CPU-private buffer, followed by code that re-constructs the interrupt stack frame and re-issues the interrupt to Granary. Granary then emulates a return from the current interrupt handler (without issuing an \texttt{iret} instruction), but leaves interrupts disabled and redirects execution into the copied code. When the copied code finishes, Granary regains control and observes the reconstructed interrupt stack frame. At this point, Granary or the tool can choose to handle the interrupt or defer the handling of the interrupt to the kernel.

%, but introduces implementation complexities and high overheads for interrupt-heavy workloads. Precise interrupt delivery is one of the ways which DRK maintains transparency: interrupt handlers only 
%The interaction between DRK's interrupt delaying mechanism and how also makes designing instrumentation subtlely harder. For example, Granary's \texttt{RCUdbg} tool injects instrumentation inside of read-side critical sections that looks for loads/stores from tainted addresses. When necessary, \texttt{RCUdbg} spills and restores registers around each checked load/store operation, so that the registers can be safely used by the checking code. This is an example of pre and post instruction instrumentation: some instructions are injected before a native instruction, and some instructions are injected after. DRK is oblivious to the relationship between pre/post instrumentation, and so an interrupt that occurs within the pre-instrumentation will only be delayed until the native instruction.

\section{Choosing What to Instrument}

\begin{figure*}[ht!]
\lstset{language=C, tabsize=2, stepnumber=1}
\begin{multicols}{2}
\begin{lstlisting}[basicstyle=\footnotesize\ttfamily]
struct device_driver {
	...
	int (*probe)(struct device *);
	int (*remove)(struct device *);
	void (*shutdown)(struct device *);
	int (*suspend)(struct device *, pm_message_t);
	int (*resume)(struct device *);
	...
	const struct dev_pm_ops *pm;
	...
};
\end{lstlisting}
\columnbreak
\begin{lstlisting}[basicstyle=\footnotesize\ttfamily]
TYPE_WRAPPER(struct device_driver, {
    PRE_OUT {
        ABORT_IF_FUNCTION_IS_WRAPPED(arg.probe)
        WRAP_FUNCTION(arg.probe);
        WRAP_FUNCTION(arg.remove);
        ...
    }
    POST_OUT {
        POST_WRAP(arg.pm);
    }
})
\end{lstlisting}
\end{multicols}
\caption{The Linux device driver structure is shown on the left. The automatically generated type wrapper for this structure is shown on the right. In the wrapper code, \texttt{arg} is a reference to a \texttt{struct device\_driver} object passed as, or referenced by, an argument to a kernel or module wrapper. Code in the \texttt{PRE\_OUT} section is applied to arguments of the wrapped type before a kernel wrapper is invoked. Similarly, code in the \texttt{POST\_OUT} section is applied to arguments of the wrapped type after a kernel wrapper is invoked. \texttt{POST\_WRAP} invokes the type wrapper that is specific to the value to which it is applied (\texttt{arg.pm}). Type wrappers also support \texttt{\_IN} suffixes instead of \texttt{\_OUT} suffixes, which apply to data going into modules (i.e., over module wrappers). Finally, the \texttt{RETURN\_} prefix is used to apply some code to return values of either kernel or module wrappers.}
\label{fig:type_wrapper}
\end{figure*}

Granary allows tool developers to precisely specify what code should be instrumented. Example granularities of instrumentation include the whole kernel, only specific modules, only specific functions, or on-demand instrumentation based on events (e.g. interrupts or exceptions).

\subsection{Kernel}
Like DRK and btkernel, Granary can instrument the whole kernel. Instrumenting the whole kernel requires interposing on the system call entrypoint (x86-64 \texttt{MSR\_LSTAR} model-specific register) and on the interrupt vector entrypoints (stored in the interrupt descriptor table). For whole-kernel instrumentation, Granary boostraps by duplicating the the early entrypoint instructions that are responsible for switching execution onto a kernel stack, and then injects a jump to translate/instrumented kernel code after the stack switch. The translation process continues when a system call or interrupt occurs and follows the jump from duplicated into translated code. Granary only translate code that is known to operate on a kernel stack so that instrumentation tools can safely save transient data in a reentrant way by spilling that data to the stack.

\subsection{Modules}


Granary can target instrumentation only at specific kernel modules, while executing the rest of the kernel natively and without overhead. Instrumenting only specific kernel modules is particularly useful for debugging tools because modules represent the bulk of new kernel code under development, and contain the most bugs \cite{FaultsInLinux}.

Granary interposes on an existing module by using hardware page protection to mark an existing module as non-executable and trap attempts to execute that module's code. Granary transparently recovers from these traps by returning execution to instrumented code. Granary takes control of dynamically loaded modules by interposing on the Linux kernel's module loading process. When a kernel module is loaded, Granary bootstraps by translating the first basic block of the module's initialization function.  It then replaces the pointer to that function with a pointer to the translated basic block. The translation process continues when the kernel initializes the module by invoking the translated module code. As with existing modules, the native code segments of dynamically loaded modules are page protected to prevent and recover from accidental execution. 

While sufficient for comprehensiveness, hardware page protection is an inefficient mechanism for gaining control of module code execution. That is, after the (instrumented) module initializer runs to completion, Granary needs an efficient way to regain control of future invocations of the module's code. Our approach to regaining control is based on the observation that modules tell the kernel about their interfaces by registering functions with the kernel. We expect that at least some of the registered functions will be executed by the kernel because this is the mechanism by which modules extend the kernel's functionality. To Granary, registered module functions represent potential future \emph{attach} points, where a switch from native to instrumented execution will occur. Furthermore, Granary discovers additional attach points at detach points by observing pointers to module functions that are passed by modules to the kernel.

Granary uses static analysis to dynamically discover attach points by wrapping the kernel/module interface. Kernel functions are wrapped by \emph{kernel wrappers} that inspect and traverse argument pointers in search of pointers to module functions. \Cref{fig:type_wrapper} shows an example of a type wrapper for the Linux device driver structure. If a pointer to a module function (a future attach point) is discovered, then Granary replaces that pointer with a function-specific \emph{module wrapper}. Granary inspects and modifies arguments to module wrappers in the same way as for kernel wrappers. This allows Granary to discover kernel entry points that will cause instrumentation to detach. Finally, Granary redirects execution to the appropriate kernel or instrumented module function after wrapping has occurred.

Kernel and module wrappers invoke \emph{type wrappers} to find and wrap pointers to module functions that are directly or indirectly referenced by kernel/module function arguments. A type wrapper is a function that recursively  traverses the in-memory object graph and converts pointers to module code into pointers to wrapped module functions. Type and kernel wrappers are automatically generated at Granary's compile time by scripts that statically analyze the kernel source code. Granary automatically matches any variable in a kernel wrapper to a type wrapper if the base type (absent pointers, specifiers, and qualifiers) of that variable matches the type wrapper's wrapped type. Similarly, Granary automatically generates module wrappers using a combination of compile-time meta-programming and runtime code generation to match type wrappers to the declared arguments of \texttt{C} function pointer types.  Granary's wrapper approach has two benefits: (i) it is more efficient than the trap-based alternative, and (ii) it gives instrumentation tools direct and semantically meaningful access to data crossing the kernel/module boundary.

After Granary bootstraps on the module initialization process, \emph{attaching} occurs in one of three ways: \begin{enumerate}
	\item {\bf Implicit attaching:} the kernel returns to instrumented module code in the code cache. This occurs when instrumented moduel code is interrupted, or when the module invokes a kernel function (detaching) and that function returns to the instrumented module code (attaching).
	\item {\bf Fast attaching:} the kernel invokes a wrapped module function. The first instance of fast attaching for any kernel module is when the kernel's module loader invokes the instrumented module initializer function.
	\item {\bf Slow attaching:} the kernel invokes unwrapped module code. If the kernel executes a module function which was passed to the kernel in a type-unsafe manner, then the processor will raise a fault because Granary uses hardware page protection to prevent module code from being executed. Granary handles these faults by returning execution to the instrumented version of the faulting module code.
\end{enumerate}

Granary \emph{detaches} when control transfers from instrumented code to native (uninstrumented) code. Detaching occurs in one of two ways: \begin{enumerate}
	\item {\bf Implicit detaching:} instrumented module code returns to the kernel code which originally invoked the module, or is interrupted (initial interrupt handling is done by the kernel).
	\item {\bf Wrapped detaching:} instrumented module code invokes a kernel wrapper, which later transfers control to the kernel.
\end{enumerate}

Granary's wrappers expose a wealth of static program information to instrumentation tools. Instrumentation tools can use information present in wrappers to alter how code is instrumented, or to simply inspect the runtime object graph in a type-safe way. For example, we are actively using type information present in wrappers to create a tool that generates models of typical module behavior. The wrapper information serves two roles in our tool. First, we use type wrappers to assign type-specific IDs to module-allocated memory that is shared across the module/kernel interface. Type ID assignment is critical because it allows us to match memory reads and writes to specific kernel data structure fields. Second, we use the kernel and module function wrappers to generate call graphs of a module's execution. This call graph models module behavior (according to the kernel) because we label module code nodes with kernel data structure and function pointer field names (derived from module wrappers). This labelling allows us to generalize across similar modules. For example, code reached by calling the \texttt{ext4\_mount} and \texttt{btrfs\_mount} functions from the \texttt{ext4} and \texttt{btrfs} file system modules, respectively, are both labelled as \texttt{file\_system\_type::mount}, because the function addresses are stored (and later replaced by module wrappers) in the \texttt{mount} field of a \texttt{file\_system\_type} data structure. The combined records from multiple ``trusted'' modules of the same class (e.g., mature, open-source file systems) models the behavior of typical kernel modules. We hope that these models will help us build tools that classify and identify spurious module behavior. 

\subsection{Functions}

\subsection{On-demand}

%\section{Mixed-Mode Execution}\label{sec:modes}
%Granary supports two modes of execution: instrumented and native. Module code is instrumented and executes from Granary's code cache, which is under Granary's control. Non-module kernel code runs natively. A mode switch occurs when execution transfers between native and instrumented code. Some mode switches happen naturally (e.g., when instrumented code returns to native code) and other mode switches are mediated by Granary (e.g., when instrumented module code invokes a kernel function).
%
%The mode switch from instrumented module code to native kernel code is easier to detect since the instrumented code runs under Granary's control. Granary treats all kernel functions as \emph{detach} points, where a mode switch from instrumented to native code occurs. At these points, Granary stops executing.
%
%However, Granary needs a way to regain control when native kernel code invokes module code. Our fallback solution for regaining control uses hardware page protection to trap attempts by the kernel to execute native module code. We handle these traps by redirecting execution to instrumented module code. While comprehensive, this approach is not ideal because: \begin{inparaenum}[i)]
%	\item trapping on every execution attempt introduces overhead; and
%	\item the trap does not provide sufficient information about which interfaces were being used by the kernel to invoke the module.
%\end{inparaenum}





\section{Context-Driven Instrumentation}\label{sec:policies}

A natural extension of mixed-mode execution is to give Granary tools the ability to dynamically switch the policy used to instrument code. Instrumenting only module code allows Granary to specialize the execution of native code. In the same way, policy switching allows tools to specialize the execution of instrumented code. In fact, optimising the performance of an early Granary tool was the original motivation for policy switching.

We developed a Granary tool that detects several Read-Copy-Update (RCU) API misuses in module code. Our tool focused on read-side critical sections (delimited by calls to \texttt{rcu\_read\_lock} and \texttt{rcu\_read\_unlock} in the code), however, most code executes outside of read-side critical sections. As an optimisation, we wanted our heavyweight API-checking instrumentation to apply only when the code was executing within a read-side critical section. Implementing this optimisation was challenging because each basic block was only translated once, and we had no way to know whether or not the heavyweight instrumentation should be applied to it. Knowing the state (within or outside a read-side critical section) at translation time was not sufficient, since the same translated block could later be executed in the opposite context. That is, code executing \emph{within} a read-side critical section may have originally been translated while executing \emph{outside} of a read-side critical section, and would thus omit the heavyweight API-checking instrumentation. This omission could cause our tool to miss bugs (i.e., it would not be comprehensive) when the basic block executes within a read-side critical section.

To implement this optimisation, Granary enables tailoring instrumentation to the context in which the instrumented code will execute. To do so, Granary allows different versions of the same module code to co-exist within Granary's code cache. That is, a different version of each of a module's basic blocks exists in Granary's code cache  for each encountered execution context. In the case of our RCU checker tool, there were two execution contexts: within and outside of a read-side critical section. If the same module basic block is  executed in the two contexts, then Granary's code cache would contain two different instrumented versions of that basic block. The way that Granary distinguishes between different execution contexts is with \emph{instrumentation policies}. 

An instrumentation policy is both a name for an execution context, as well as a function that decides how to instrument basic blocks that will execute within that context. All tools define an initial policy that Granary uses to instrument module code. Tools are not limited to one policy though: any policy can declare a policy switch that will take effect when a selected control-transferring instruction (CTI) is executed. For example, our RCU tool invokes a policy switch from policy $P_{\mathit{null}}$ to policy $P_{\mathit{read\_critical}}$ when $P_{\mathit{null}}$'s instrumentation function observes a \texttt{call} instruction to the \texttt{rcu\_read\_lock} Linux kernel function.

Because policies name an execution context, they also represent states in a finite state machine. That is, a module's execution is in the state named by a policy if the code executing was instrumented by that policy. A state transition occurs when control transfers from code instrumented by one policy to code instrumented by another policy. A limitation with this approach is that a single state does not encode the sequence of previous states that led to execution being in the current state. For example, RCU permits nested read-side critical sections. If two read-side critical sections are nested then switching from $P_{\mathit{read\_critical}}$ to $P_{\mathit{null}}$ on the first \texttt{call} to \texttt{rcu\_read\_unlock} meant that our tool would lose track of being in the context of the outer read-side critical section. We solved this limitation by observing that, in most cases, function returns are natural policy reverting points. This is because the runtime call stack encodes both the context in which the current code is executing, as well as the continuation of the current executing code.

The effect of a tool specifying a policy switch on a CTI is that the basic block(s) targeted by that CTI will be instrumented according to the specified policy. CTIs with unspecified policies inherit their policies from their containing basic blocks. As hinted at above, \texttt{ret} instructions cannot explicitly switch policies, which allows a function instrumented by a different policy than its caller to return to the caller's context (i.e., policy). The asymmetry between \texttt{call}s and \texttt{ret}s is intentional: \texttt{call}s place contextual breadcrumbs (in the form of return addresses) on the runtime call stack, and \texttt{ret}s read these breadcrumbs to return to a previous context. Under this lens, the instruction pointer tracks our current policy, and return addresses form a stack of previous policies. Policy switches behave similarly to state transitions in a pushdown automaton; \texttt{call} instructions push a new state onto the stack for each function, \texttt{ret} instructions pop the current function's state from the stack, and other CTIs induce state transitions within the current function by altering control flow.

Granary implements policy tracking and switching by encoding policy information into the meta-data and CTIs of basic blocks. If a policy switch is not specified on an instrumented CTI then that CTI inherits the policy used to instrument the basic block containing the CTI. When an instrumented CTI executes for the first time, it yields control to Granary with the CTI target and policy information as inputs. Granary decodes and instruments the targeted instructions according to the input policy information. Because every non-\texttt{ret} CTI encodes policy information, and because Granary's translation mechanism depends only on CTI policy and target information, Granary is able to ensure that policy information is never lost or corrupted, even in the face of concurrent executions of the same module code, arbitrary pre-emption, and arbitrary resumption.


%\section{Reifying Instrumentation}\label{sec:reify}
%
%Granary uses a technique we call \emph{reifying instrumentation} to provide the benefits of high-level static analysis information to dynamic instrumentation tools. Reifying instrumentation bootstraps on 

\section{Evaluation}\label{sec:eval}


\section{Related Work}\label{sec:related}
Prior work can be classified as either whole-kernel/system DBT, or probe-based kernel instrumentation. We discuss how Granary differs from these approaches.
\vspace{-3pt}\paragraph{Whole-kernel/system DBT} DRK \cite{DRK} is a kernel space port of the DynamoRIO \cite{DynamoRIO} DBT framework. DRK instruments the entire kernel, including modules, and follows a strict transparency model, which limits the flexibility of instrumentation and increases overheads.  PinOS \cite{PinOS} is a port of the Pin \cite{Pin} DBT framework that performs whole-system instrumentation. It has high overheads and depends on hardware virtualization, which prevents it from instrumenting non-virtualizable kernel modules. 

\vspace{-3pt}\paragraph{Probe-based Instrumentation} Several systems support injecting code at specific locations within kernel code. For example, KernInst \cite{KernInst} can inject code at almost any location in an unmodified commodity OS. Other examples with similar or more restricted functionality include LTTng \cite{LTTng}, KProbes \cite{KProbes}, DProbes \cite{DProbes}, and ftrace \cite{ftrace}. These systems are unable to perform fine-grained instrumentation of instructions or memory.


\section{Conclusion}\label{sec:conclusion}
%We created Granary to address the challenges of instrumenting binary kernel modules.  Granary provides mixed-mode execution to remove the overheads of DBT for uninstrumented kernel code.  A relaxed transparency model further improves performance and allows greater visibility into the interactions between module and kernel code.  Granary also supports policy-driven instrumentation, which allows tools to specialize their instrumentation based on the context in which code executes.  Finally, Granary exposes high-level static analysis information to dynamic instrumentation tools, making it easy to match low-level memory reads with specific fields in data structures at the source code level. 

%Together, Granary's features simplify the development of powerful kernel module analysis tools, while delivering lower overheads than previous kernel dynamic binary instrumentation solutions.

\bibliographystyle{acm}
\bibliography{library}

\end{document}
